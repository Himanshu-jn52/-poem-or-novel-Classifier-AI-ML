{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poemVSnovel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7PL3LZMixmJ8AEzl08Krn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himanshu-jn52/-poem-or-novel-Classifier-AI-ML/blob/main/poemVSnovel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries."
      ],
      "metadata": {
        "id": "8R4EpPQEO3nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TygpPowdLjer",
        "outputId": "37f15ce7-e6c8-4e7e-84fe-a8b224084218"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "BpfKhVCATw4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting required infromation from dataset provided and adding to the dataframe.\n",
        "Dataframe has two columns:\n",
        "1.   Content - contents of Poem and Novel\n",
        "2.   Index - for Poem = 0 and for Novel = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "jA2gAqtjO7JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df1 = pd.read_csv(\"Dataset/all.csv\",usecols=[\"author\", \"content\", \"poem name\", \"age\",\"type\"])\n",
        "df2 = pd.read_csv(\"Dataset/booksummaries600.txt\",delimiter = \"\\t\",header=None)\n",
        "df2 = df2.drop([0,1], axis = 1)\n",
        "df2.columns = [\"novel name\", \"author\", \"date\", \"type\", \"content\"]\n",
        "\n",
        "for x in df1[\"content\"][:500]:\n",
        "    try:\n",
        "      df = df.append([[x, 0]],ignore_index=True)\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "for x in df2[\"content\"][0:500]:\n",
        "    try:\n",
        "      df = df.append([[x, 1]],ignore_index=True)\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "df.columns = ['Content', 'Index']"
      ],
      "metadata": {
        "id": "tvl672tDpoUB"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the data "
      ],
      "metadata": {
        "id": "VuoRD3XnPT2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data = []             #to store cleaned data\n",
        "for i in range(0, 1000):\n",
        "  content = re.sub('[^a-zA-Z]', ' ', df['Content'][i])    #to replace all character & punctuation with white space\n",
        "  content = content.lower()        \n",
        "  content = content.split()\n",
        "  ps = PorterStemmer()   # Creating an stem object\n",
        "  all_stopwords = stopwords.words('english')   # collecting all the stopwords in english\n",
        "  content = [ps.stem(word) for word in content if not word in set(all_stopwords)] # removing stopwords from contents\n",
        "  content = ' '.join(content)\n",
        "  cleaned_data.append(content)"
      ],
      "metadata": {
        "id": "rADxUUJ3WZba"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting contents into binary format (Creating BOW)"
      ],
      "metadata": {
        "id": "iVkr8CVqSz4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(max_features = 1500)\n",
        "X = cv.fit_transform(cleaned_data).toarray() #fit and transform to vector\n",
        "y = df.iloc[:, -1].values\n"
      ],
      "metadata": {
        "id": "1DwtaWccWdBd"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELLING & TRAINING**"
      ],
      "metadata": {
        "id": "qq9hGTwET8lE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating train & test data with test size of 20%."
      ],
      "metadata": {
        "id": "cbDTQsRlUWIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "EyXyVxuuWdLq"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining two methods of Naive - Bayes\n",
        "\n",
        "1.  Gaussian Naive Bayes\n",
        "2.  Multinomial Naive Bayes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gxDUl4QnVTAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gaussian Naive Bayes\n",
        "Gclassifier = GaussianNB() \n",
        "Gclassifier.fit(X_train, y_train)\n",
        "\n",
        "#Multinomial Naive Bayes\n",
        "Mclassifier = MultinomialNB()\n",
        "Mclassifier.fit(X_train, y_train)\n",
        "\n",
        "print(Gclassifier.score(X_test,y_test)) #---> 0.905\n",
        "print(Mclassifier.score(X_test,y_test)) #---> 0.98 will proceed with Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "K3K0NK13WdUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ee59ac-7e2e-4f72-e0c7-1e7515213155"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.905\n",
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing prediction for Multinomial Naive Bayes "
      ],
      "metadata": {
        "id": "V5SJsBriXlBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = Mclassifier.predict(X_test)\n",
        "np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)"
      ],
      "metadata": {
        "id": "JFXXBah_WdcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f573c336-805a-4c4b-99fa-db74e8604368"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will evaluate the modela and check the accuracy score."
      ],
      "metadata": {
        "id": "lHXLbnD2X3Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ewENvNqYWdly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc59dbb-d6a3-4f53-ea6f-3a75044fc259"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 94   4]\n",
            " [  0 102]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# dump trained model to pickle file\n",
        "pickle.dump(Mclassifier, open(\"model.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "lQLziMIwH-Qw"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python \"/content/Main.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "DOUWRr4xaIno",
        "outputId": "a572542b-649b-442e-8d5e-ce7c2b97df5f"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-111-7aa207535389>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python \"/content/Main.py\"\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}