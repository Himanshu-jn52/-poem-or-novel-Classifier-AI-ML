{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poemVSnovel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeScieVpuKor4hsOK/vV3g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himanshu-jn52/-poem-or-novel-Classifier-AI-ML/blob/main/poemVSnovel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries."
      ],
      "metadata": {
        "id": "8R4EpPQEO3nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TygpPowdLjer",
        "outputId": "37f15ce7-e6c8-4e7e-84fe-a8b224084218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "BpfKhVCATw4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting required infromation from dataset provided and adding to the dataframe.\n",
        "Dataframe has two columns:\n",
        "1.   Content - contents of Poem and Novel\n",
        "2.   Index - for Poem = 0 and for Novel = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "jA2gAqtjO7JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df1 = pd.read_csv(\"Dataset/all.csv\",usecols=[\"author\", \"content\", \"poem name\", \"age\",\"type\"])\n",
        "df2 = pd.read_csv(\"Dataset/booksummaries600.txt\",delimiter = \"\\t\",header=None)\n",
        "df2 = df2.drop([0,1], axis = 1)\n",
        "df2.columns = [\"novel name\", \"author\", \"date\", \"type\", \"content\"]\n",
        "\n",
        "for x in df1[\"content\"][:500]:\n",
        "    try:\n",
        "      df = df.append([[x, 0]],ignore_index=True)\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "for x in df2[\"content\"][0:500]:\n",
        "    try:\n",
        "      df = df.append([[x, 1]],ignore_index=True)\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "df.columns = ['Content', 'Index']"
      ],
      "metadata": {
        "id": "tvl672tDpoUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the data "
      ],
      "metadata": {
        "id": "VuoRD3XnPT2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data = []             #to store cleaned data\n",
        "for i in range(0, 1000):\n",
        "  content = re.sub('[^a-zA-Z]', ' ', df['Content'][i])    #to replace all character & punctuation with white space\n",
        "  content = content.lower()        \n",
        "  content = content.split()\n",
        "  ps = PorterStemmer()   # Creating an stem object\n",
        "  all_stopwords = stopwords.words('english')   # collecting all the stopwords in english\n",
        "  content = [ps.stem(word) for word in content if not word in set(all_stopwords)] # removing stopwords from contents\n",
        "  content = ' '.join(content)\n",
        "  cleaned_data.append(content)"
      ],
      "metadata": {
        "id": "rADxUUJ3WZba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting contents into binary format (Creating BOW)"
      ],
      "metadata": {
        "id": "iVkr8CVqSz4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(max_features = 1500)\n",
        "X = cv.fit_transform(cleaned_data).toarray() #fit and transform to vector\n",
        "y = df.iloc[:, -1].values\n"
      ],
      "metadata": {
        "id": "1DwtaWccWdBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELLING & TRAINING**"
      ],
      "metadata": {
        "id": "qq9hGTwET8lE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating train & test data with test size of 20%."
      ],
      "metadata": {
        "id": "cbDTQsRlUWIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "EyXyVxuuWdLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining two methods of Naive - Bayes\n",
        "\n",
        "1.  Gaussian Naive Bayes\n",
        "2.  Multinomial Naive Bayes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gxDUl4QnVTAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gaussian Naive Bayes\n",
        "Gclassifier = GaussianNB() \n",
        "Gclassifier.fit(X_train, y_train)\n",
        "\n",
        "#Multinomial Naive Bayes\n",
        "Mclassifier = MultinomialNB()\n",
        "Mclassifier.fit(X_train, y_train)\n",
        "\n",
        "print(Gclassifier.score(X_test,y_test)) #---> 0.905\n",
        "print(Mclassifier.score(X_test,y_test)) #---> 0.98 will proceed with Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "K3K0NK13WdUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ee59ac-7e2e-4f72-e0c7-1e7515213155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.905\n",
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing prediction for Multinomial Naive Bayes "
      ],
      "metadata": {
        "id": "V5SJsBriXlBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = Mclassifier.predict(X_test)\n",
        "np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)"
      ],
      "metadata": {
        "id": "JFXXBah_WdcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will evaluate the modela and check the accuracy score."
      ],
      "metadata": {
        "id": "lHXLbnD2X3Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ewENvNqYWdly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc59dbb-d6a3-4f53-ea6f-3a75044fc259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 94   4]\n",
            " [  0 102]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# dump trained model to pickle file\n",
        "pickle.dump(Mclassifier, open(\"model.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "lQLziMIwH-Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling main function\n",
        "\n",
        "def getType(content, loaded_model):\n",
        "  content = re.sub('[^a-zA-Z]', ' ', content)\n",
        "  content = content.lower()\n",
        "  content = content.split()\n",
        "  ps = PorterStemmer()\n",
        "  all_stopwords = stopwords.words('english')\n",
        "  content = [ps.stem(word) for word in content if not word in set(all_stopwords)]\n",
        "  content = ' '.join(content)\n",
        "  corpus = [content]\n",
        "  #cv = CountVectorizer(max_features = 1500)\n",
        "  new_X_test = cv.transform(corpus).toarray()\n",
        "  new_y_pred = loaded_model.predict(new_X_test)\n",
        "  return new_y_pred\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  loaded_model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
        "  output = getType(str(input(\"Enter content...\")), loaded_model)\n",
        "  if output[0]==1:\n",
        "    print(\"Novel\")\n",
        "  else :\n",
        "    print(\"Poem\")"
      ],
      "metadata": {
        "id": "ppSguQrL2CDf",
        "outputId": "f03fc8b2-b91b-4522-84af-e57c8af4e563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter content...Alex, a teenager living in near-future England, leads his gang on nightly orgies of opportunistic, random \"ultra-violence.\" Alex's friends (\"droogs\" in the novel's Anglo-Russian slang, Nadsat) are: Dim, a slow-witted bruiser who is the gang's muscle; Georgie, an ambitious second-in-command; and Pete, who mostly plays along as the droogs indulge their taste for ultra-violence. Characterized as a sociopath and a hardened juvenile delinquent, Alex is also intelligent and quick-witted, with sophisticated taste in music, being particularly fond of Beethoven, or \"Lovely Ludwig Van.\" The novel begins with the droogs sitting in their favorite hangout (the Korova Milkbar), drinking milk-drug cocktails, called \"milk-plus\", to hype themselves for the night's mayhem. They assault a scholar walking home from the public library, rob a store leaving the owner and his wife bloodied and unconscious, stomp a panhandling derelict, then scuffle with a rival gang. Joyriding through the countryside in a stolen car, they break into an isolated cottage and maul the young couple living there, beating the husband and raping his wife\n",
            "Novel\n"
          ]
        }
      ]
    }
  ]
}